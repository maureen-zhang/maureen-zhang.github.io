{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0379f37075f9434da08478d0fba15ee2",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Train an XOR network using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8d31132ea4fb4917a9eb76428cf3b411",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "# XOR Problem and Neural Networks\n",
    "The XOR (exclusive OR) problem is a fundamental problem in machine learning and neural networks. It demonstrates the limitations of linear classifiers and highlights the necessity of hidden layers for solving non-linearly separable problems. The XOR function outputs `1` when inputs differ and `0` when they are the same:\n",
    "\n",
    "| Input X1 | Input X2 | Output y|\n",
    "|---------|---------|--------|\n",
    "| 0       | 0       | 0      |\n",
    "| 0       | 1       | 1      |\n",
    "| 1       | 0       | 1      |\n",
    "| 1       | 1       | 0      |\n",
    "\n",
    "A simple perceptron cannot solve XOR since it is not linearly separable. However, a neural network with a hidden layer can model this function effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "93895b9716ac4fd6b44a0ea9cdb1a89c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1403,
    "execution_start": 1715548750952,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "fe3ddb7f29a24769b8d349cdeabd2ca1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 152,
    "execution_start": 1715548807208,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "X = torch.tensor(\n",
    "    [\n",
    "        [0.,0],\n",
    "        [1,0],\n",
    "        [0,1],\n",
    "        [1,1]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2075e7801e0a48deb590b9fbadfa68aa",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1715548833045,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "y_true = torch.tensor(\n",
    "    [\n",
    "        [0.],\n",
    "        [1],\n",
    "        [1],\n",
    "        [0]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide the number of hidden layers, the number of neurons, and the activation function for each neuron. This is sufficient to build a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ad5416dbad9c4914b9c06079688032ea",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1646,
    "execution_start": 1715549110306,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "d_in = 2\n",
    "d_hidden = 2\n",
    "d_out = 1\n",
    "\n",
    "# Define the model with an input layer, hidden layer, and output layer\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(d_in, d_hidden),  # Input layer to hidden layer\n",
    "    nn.ReLU(),                  # Activation function for hidden layer\n",
    "    nn.Linear(d_hidden, d_out), # Hidden layer to output layer\n",
    "    nn.Sigmoid()                # Activation function for output layer\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "845a1a2da9af49d38b58949e90f15384",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 80,
    "execution_start": 1715549219664,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# This test will fail until you implement the training loop\n",
    "# The training loop is implemented in the next cell\n",
    "y_hat = model(X)\n",
    "print(y_hat)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer and loss function\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent optimizer\n",
    "loss_fn = nn.BCELoss()  # Binary Cross Entropy loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A successful prediction using gradient descent should have a decreasing loss. Use the following code to print out your loss function every 100 iterations:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "for i in range(2000):\n",
    "    y_hat = model(X)\n",
    "    loss = loss_fn(y_hat, y_true)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if i % 100 == 0:\n",
    "        print(i, loss.item())            \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to test the out put od X! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print neuron weights and biases\n",
    "print(\"Neuron Weights and Biases:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}:\\n{param.data}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "87434ff0419a4d00bf58e6a9d1aea641",
  "deepnote_persisted_session": {
   "createdAt": "2024-05-12T21:34:26.572Z"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
